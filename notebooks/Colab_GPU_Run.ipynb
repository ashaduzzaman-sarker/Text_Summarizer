{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ashaduzzaman-sarker/Text_Summarizer.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phAMe1GK1__H",
        "outputId": "729393b9-5085-48d3-fc1d-6a2e9f2147e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Text_Summarizer'...\n",
            "remote: Enumerating objects: 217, done.\u001b[K\n",
            "remote: Counting objects: 100% (217/217), done.\u001b[K\n",
            "remote: Compressing objects: 100% (134/134), done.\u001b[K\n",
            "remote: Total 217 (delta 99), reused 177 (delta 62), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (217/217), 12.75 MiB | 11.19 MiB/s, done.\n",
            "Resolving deltas: 100% (99/99), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Text_Summarizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KM9gh5E5Tdr",
        "outputId": "32233870-bb49-402f-b6d8-658f3d2f05ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Text_Summarizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R-funRE5TFg",
        "outputId": "ee7b50be-d563-484d-810a-b22404d30548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py\tDockerfile  main.py    project_template.py  README.md\t      src\n",
            "config\tLICENSE     notebooks  pyproject.toml\t    requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies from requirements.txt\n",
        "%pip install -r requirements.txt -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhXSgNGb_rTO",
        "outputId": "65afaed1-5361-4be2-824f-1834ef5adf77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.2/466.2 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.8/438.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.0/97.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.7/51.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m429.9/429.9 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.5/375.5 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m752.6/752.6 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.1/753.1 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building editable for textSummarizer (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELzp-PTy-gYZ",
        "outputId": "e404166d-1804-4cb5-e50e-4b5326544fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-25 22:06:51,116: INFO: utils: NumExpr defaulting to 2 threads.]\n",
            "[2025-10-25 22:06:52,484: INFO: config: TensorFlow version 2.19.0 available.]\n",
            "[2025-10-25 22:06:52,488: INFO: config: JAX version 0.7.2 available.]\n",
            "2025-10-25 22:07:09.287226: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761430029.310151    1330 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761430029.317439    1330 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761430029.334856    1330 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761430029.334898    1330 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761430029.334903    1330 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761430029.334907    1330 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-25 22:07:09.340351: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[2025-10-25 22:07:16,011: INFO: main: ============================================================]\n",
            "[2025-10-25 22:07:16,011: INFO: stage_01_data_ingestion: >>>>>> Stage: Data Ingestion started <<<<<<]\n",
            "[2025-10-25 22:07:16,015: INFO: common: Loaded config from config/config.yaml]\n",
            "[2025-10-25 22:07:16,018: INFO: common: Loaded config from config/params.yaml]\n",
            "[2025-10-25 22:07:16,018: INFO: common: Created directory: artifacts]\n",
            "[2025-10-25 22:07:16,019: INFO: common: Created directory: artifacts/data_ingestion]\n",
            "[2025-10-25 22:07:16,019: INFO: data_ingestion: Loading dataset: abisee/cnn_dailymail]\n",
            "[2025-10-25 22:07:16,019: INFO: data_ingestion: Config: 3.0.0, Split: train]\n",
            "README.md: 15.6kB [00:00, 43.3MB/s]\n",
            "3.0.0/train-00000-of-00003.parquet: 100% 257M/257M [00:04<00:00, 53.6MB/s]\n",
            "3.0.0/train-00001-of-00003.parquet: 100% 257M/257M [00:03<00:00, 67.2MB/s]\n",
            "3.0.0/train-00002-of-00003.parquet: 100% 259M/259M [00:07<00:00, 34.1MB/s]\n",
            "3.0.0/validation-00000-of-00001.parquet: 100% 34.7M/34.7M [00:00<00:00, 59.1MB/s]\n",
            "3.0.0/test-00000-of-00001.parquet: 100% 30.0M/30.0M [00:00<00:00, 42.1MB/s]\n",
            "Generating train split: 100% 287113/287113 [00:08<00:00, 33265.21 examples/s]\n",
            "Generating validation split: 100% 13368/13368 [00:00<00:00, 56141.71 examples/s]\n",
            "Generating test split: 100% 11490/11490 [00:00<00:00, 52225.85 examples/s]\n",
            "[2025-10-25 22:07:48,601: INFO: data_ingestion: Limited dataset: 287113 -> 1000 samples]\n",
            "[2025-10-25 22:07:48,602: INFO: data_ingestion: Dataset loaded: 1000 samples]\n",
            "[2025-10-25 22:07:48,602: INFO: data_ingestion: Features: ['article', 'highlights', 'id']]\n",
            "Saving the dataset (1/1 shards): 100% 1000/1000 [00:00<00:00, 119407.39 examples/s]\n",
            "[2025-10-25 22:07:48,613: INFO: data_ingestion: Dataset saved to: artifacts/data_ingestion/dataset]\n",
            "[2025-10-25 22:07:48,613: INFO: stage_01_data_ingestion: >>>>>> Stage: Data Ingestion completed <<<<<<\n",
            "]\n",
            "[2025-10-25 22:07:48,614: INFO: main: ============================================================]\n",
            "[2025-10-25 22:07:48,614: INFO: stage_02_data_validation: >>>>>> Stage: Data Validation started <<<<<<]\n",
            "[2025-10-25 22:07:48,631: INFO: common: Loaded config from config/config.yaml]\n",
            "[2025-10-25 22:07:48,645: INFO: common: Loaded config from config/params.yaml]\n",
            "[2025-10-25 22:07:48,646: INFO: common: Created directory: artifacts]\n",
            "[2025-10-25 22:07:48,646: INFO: common: Created directory: artifacts/data_validation]\n",
            "[2025-10-25 22:07:48,646: INFO: data_validation: Starting data validation]\n",
            "[2025-10-25 22:07:48,646: INFO: data_validation: Dataset directory found: artifacts/data_ingestion/dataset]\n",
            "[2025-10-25 22:07:48,646: INFO: data_validation: Loading dataset from artifacts/data_ingestion/dataset]\n",
            "[2025-10-25 22:07:48,653: INFO: data_validation: Dataset columns: ['article', 'highlights', 'id']]\n",
            "[2025-10-25 22:07:48,654: INFO: data_validation: All required columns present]\n",
            "[2025-10-25 22:07:48,656: INFO: data_validation: Dataset size: 1000 samples]\n",
            "[2025-10-25 22:07:48,691: INFO: data_validation: Data quality checks passed]\n",
            "[2025-10-25 22:07:48,692: INFO: data_validation: Validation status written to artifacts/data_validation/status.txt]\n",
            "[2025-10-25 22:07:48,692: INFO: data_validation: All validation checks passed]\n",
            "[2025-10-25 22:07:48,692: INFO: stage_02_data_validation: >>>>>> Stage: Data Validation completed <<<<<<\n",
            "]\n",
            "[2025-10-25 22:07:48,692: INFO: main: ============================================================]\n",
            "[2025-10-25 22:07:48,692: INFO: stage_03_data_transformation: >>>>>> Stage: Data Transformation started <<<<<<]\n",
            "[2025-10-25 22:07:48,696: INFO: common: Loaded config from config/config.yaml]\n",
            "[2025-10-25 22:07:48,699: INFO: common: Loaded config from config/params.yaml]\n",
            "[2025-10-25 22:07:48,699: INFO: common: Created directory: artifacts]\n",
            "[2025-10-25 22:07:48,699: INFO: common: Created directory: artifacts/data_transformation]\n",
            "[2025-10-25 22:07:48,699: INFO: data_transformation: Starting data transformation]\n",
            "[2025-10-25 22:07:48,699: INFO: data_transformation: Loading tokenizer: facebook/bart-large-cnn]\n",
            "config.json: 1.58kB [00:00, 10.2MB/s]\n",
            "vocab.json: 899kB [00:00, 90.5MB/s]\n",
            "merges.txt: 456kB [00:00, 114MB/s]\n",
            "tokenizer.json: 1.36MB [00:00, 119MB/s]\n",
            "[2025-10-25 22:07:51,478: INFO: data_transformation: Tokenizer loaded successfully]\n",
            "[2025-10-25 22:07:51,478: INFO: data_transformation: Loading dataset from artifacts/data_ingestion/dataset]\n",
            "[2025-10-25 22:07:51,481: INFO: data_transformation: Dataset loaded: 1000 samples]\n",
            "[2025-10-25 22:07:51,482: INFO: data_transformation: Tokenizing dataset...]\n",
            "Tokenizing: 100% 1000/1000 [00:02<00:00, 395.74 examples/s]\n",
            "[2025-10-25 22:07:54,038: INFO: data_transformation: Tokenization complete: 1000 samples]\n",
            "[2025-10-25 22:07:54,038: INFO: data_transformation: Features: ['input_ids', 'attention_mask', 'labels']]\n",
            "Saving the dataset (1/1 shards): 100% 1000/1000 [00:00<00:00, 126038.34 examples/s]\n",
            "[2025-10-25 22:07:54,048: INFO: data_transformation: Transformed dataset saved to: artifacts/data_transformation/tokenized_dataset]\n",
            "[2025-10-25 22:07:54,108: INFO: data_transformation: Tokenizer saved to: artifacts/data_transformation/tokenizer]\n",
            "[2025-10-25 22:07:54,109: INFO: stage_03_data_transformation: >>>>>> Stage: Data Transformation completed <<<<<<\n",
            "]\n",
            "[2025-10-25 22:07:54,122: INFO: main: ============================================================]\n",
            "[2025-10-25 22:07:54,122: INFO: stage_04_model_trainer: >>>>>> Stage: Model Training started <<<<<<]\n",
            "[2025-10-25 22:07:54,125: INFO: common: Loaded config from config/config.yaml]\n",
            "[2025-10-25 22:07:54,128: INFO: common: Loaded config from config/params.yaml]\n",
            "[2025-10-25 22:07:54,129: INFO: common: Created directory: artifacts]\n",
            "[2025-10-25 22:07:54,129: INFO: common: Created directory: artifacts/model_trainer]\n",
            "[2025-10-25 22:07:54,129: INFO: model_trainer: Starting model training]\n",
            "[2025-10-25 22:07:54,129: INFO: model_trainer: Loading tokenized dataset from artifacts/data_transformation/tokenized_dataset]\n",
            "[2025-10-25 22:07:54,133: INFO: model_trainer: Dataset loaded: 1000 samples]\n",
            "[2025-10-25 22:07:54,133: INFO: model_trainer: Splitting dataset: 90% train]\n",
            "[2025-10-25 22:07:54,140: INFO: model_trainer: Train samples: 900]\n",
            "[2025-10-25 22:07:54,140: INFO: model_trainer: Validation samples: 100]\n",
            "[2025-10-25 22:07:54,140: INFO: model_trainer: Loading tokenizer from artifacts/data_transformation/tokenizer]\n",
            "[2025-10-25 22:07:54,297: INFO: model_trainer: Loading model: facebook/bart-large-cnn]\n",
            "model.safetensors: 100% 1.63G/1.63G [00:39<00:00, 41.4MB/s]\n",
            "generation_config.json: 100% 363/363 [00:00<00:00, 2.87MB/s]\n",
            "[2025-10-25 22:08:35,380: INFO: model_trainer: Model and tokenizer loaded successfully]\n",
            "[2025-10-25 22:08:35,712: INFO: model_trainer: Training arguments configured]\n",
            "[2025-10-25 22:08:35,712: INFO: model_trainer: Total epochs: 3]\n",
            "[2025-10-25 22:08:35,712: INFO: model_trainer: Batch size: 4]\n",
            "[2025-10-25 22:08:35,712: INFO: model_trainer: Learning rate: 5e-05]\n",
            "[2025-10-25 22:08:36,468: INFO: model_trainer: Training started...]\n",
            "{'loss': 4.0358, 'grad_norm': 11.17556095123291, 'learning_rate': 9.900000000000002e-06, 'epoch': 1.76}\n",
            "{'train_runtime': 442.3104, 'train_samples_per_second': 6.104, 'train_steps_per_second': 0.387, 'train_loss': 2.6250500818442184, 'epoch': 3.0}\n",
            "100% 171/171 [07:22<00:00,  2.59s/it]\n",
            "[2025-10-25 22:16:53,288: INFO: model_trainer: Training completed!]\n",
            "[2025-10-25 22:16:53,294: INFO: model_trainer: Final model saved to: artifacts/model_trainer/final_model]\n",
            "[2025-10-25 22:16:53,294: INFO: model_trainer: Training loss: 2.6251]\n",
            "[2025-10-25 22:16:53,294: INFO: model_trainer: Training metrics saved to: artifacts/model_trainer/training_metrics.txt]\n",
            "[2025-10-25 22:16:53,295: INFO: stage_04_model_trainer: >>>>>> Stage: Model Training completed <<<<<<\n",
            "]\n",
            "[2025-10-25 22:16:53,307: INFO: main: ============================================================]\n",
            "[2025-10-25 22:16:53,307: INFO: stage_05_model_evaluation: >>>>>> Stage: Model Evaluation started <<<<<<]\n",
            "[2025-10-25 22:16:53,311: INFO: common: Loaded config from config/config.yaml]\n",
            "[2025-10-25 22:16:53,315: INFO: common: Loaded config from config/params.yaml]\n",
            "[2025-10-25 22:16:53,315: INFO: common: Created directory: artifacts]\n",
            "[2025-10-25 22:16:53,315: INFO: common: Created directory: artifacts/model_evaluation]\n",
            "[2025-10-25 22:16:53,315: INFO: model_evaluation: Starting model evaluation]\n",
            "[2025-10-25 22:16:53,316: INFO: model_evaluation: Loading tokenizer from artifacts/model_trainer/final_model]\n",
            "[2025-10-25 22:16:53,511: INFO: model_evaluation: Loading model from artifacts/model_trainer/final_model]\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/bart/configuration_bart.py:177: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
            "  warnings.warn(\n",
            "[2025-10-25 22:16:54,496: INFO: model_evaluation: Model moved to GPU]\n",
            "[2025-10-25 22:16:54,497: INFO: model_evaluation: Model and tokenizer loaded successfully]\n",
            "[2025-10-25 22:16:54,497: INFO: model_evaluation: Loading dataset from artifacts/data_transformation/tokenized_dataset]\n",
            "[2025-10-25 22:16:54,549: INFO: model_evaluation: Test dataset loaded: 100 samples]\n",
            "Downloading builder script: 6.27kB [00:00, 17.8MB/s]\n",
            "[2025-10-25 22:16:57,711: INFO: model_evaluation: ROUGE metric loaded]\n",
            "[2025-10-25 22:16:57,711: INFO: model_evaluation: Generating predictions...]\n",
            "  0% 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py:1733: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n",
            "100% 13/13 [02:01<00:00,  9.35s/it]\n",
            "[2025-10-25 22:18:59,262: INFO: model_evaluation: Generated 100 predictions]\n",
            "[2025-10-25 22:18:59,262: INFO: model_evaluation: Calculating ROUGE metrics...]\n",
            "[2025-10-25 22:18:59,272: INFO: rouge_scorer: Using default tokenizer.]\n",
            "[2025-10-25 22:18:59,880: INFO: model_evaluation: Metrics calculated:]\n",
            "[2025-10-25 22:18:59,880: INFO: model_evaluation:   rouge1: 0.4153]\n",
            "[2025-10-25 22:18:59,880: INFO: model_evaluation:   rouge2: 0.1918]\n",
            "[2025-10-25 22:18:59,880: INFO: model_evaluation:   rougeL: 0.2972]\n",
            "[2025-10-25 22:18:59,881: INFO: model_evaluation:   rougeLsum: 0.3924]\n",
            "[2025-10-25 22:18:59,881: INFO: model_evaluation: Metrics saved to artifacts/model_evaluation/metrics.json]\n",
            "[2025-10-25 22:18:59,901: INFO: model_evaluation: Predictions saved to artifacts/model_evaluation/predictions.csv]\n",
            "[2025-10-25 22:18:59,902: INFO: model_evaluation: Report saved to artifacts/model_evaluation/evaluation_report.txt]\n",
            "[2025-10-25 22:18:59,902: INFO: model_evaluation: Evaluation completed successfully]\n",
            "[2025-10-25 22:18:59,902: INFO: stage_05_model_evaluation: >>>>>> Stage: Model Evaluation completed <<<<<<\n",
            "]\n",
            "[2025-10-25 22:18:59,902: INFO: main: \n",
            "Final Evaluation Metrics:]\n",
            "[2025-10-25 22:18:59,902: INFO: main:   rouge1: 0.4153]\n",
            "[2025-10-25 22:18:59,902: INFO: main:   rouge2: 0.1918]\n",
            "[2025-10-25 22:18:59,902: INFO: main:   rougeL: 0.2972]\n",
            "[2025-10-25 22:18:59,902: INFO: main:   rougeLsum: 0.3924]\n",
            "[2025-10-25 22:18:59,902: INFO: main: ============================================================]\n",
            "[2025-10-25 22:18:59,902: INFO: main: All pipeline stages completed successfully!]\n",
            "[2025-10-25 22:18:59,902: INFO: main: Trained model: artifacts/model_trainer/final_model]\n",
            "[2025-10-25 22:18:59,902: INFO: main: Evaluation report: artifacts/model_evaluation/evaluation_report.txt]\n",
            "[2025-10-25 22:18:59,902: INFO: main: Metrics: artifacts/model_evaluation/metrics.json]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c9af1eb5",
        "outputId": "95a7beae-86df-40ad-8828-6c0e6bf898b7"
      },
      "source": [
        "!zip -r /content/artifacts.zip /content/Text_Summarizer/artifacts\n",
        "from google.colab import files\n",
        "# files.download('/content/artifacts.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/Text_Summarizer/artifacts/ (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/ (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/final_model/ (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/final_model/config.json (deflated 62%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/final_model/model.safetensors (deflated 10%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/final_model/merges.txt (deflated 53%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/final_model/vocab.json (deflated 59%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/final_model/special_tokens_map.json (deflated 85%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/final_model/tokenizer_config.json (deflated 73%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/final_model/tokenizer.json (deflated 82%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/final_model/generation_config.json (deflated 46%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/final_model/training_args.bin (deflated 53%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/training_metrics.txt (deflated 22%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/checkpoints/ (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/checkpoints/checkpoint-6/ (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/checkpoints/checkpoint-6/config.json (deflated 62%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/checkpoints/checkpoint-6/model.safetensors (deflated 10%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/checkpoints/checkpoint-6/optimizer.pt (deflated 8%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/checkpoints/checkpoint-6/trainer_state.json (deflated 56%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/checkpoints/checkpoint-6/merges.txt (deflated 53%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/checkpoints/checkpoint-6/vocab.json (deflated 59%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/checkpoints/checkpoint-6/special_tokens_map.json (deflated 85%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/checkpoints/checkpoint-6/tokenizer_config.json (deflated 73%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/checkpoints/checkpoint-6/tokenizer.json (deflated 82%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/checkpoints/checkpoint-6/rng_state.pth (deflated 26%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/checkpoints/checkpoint-6/scheduler.pt (deflated 61%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/checkpoints/checkpoint-6/generation_config.json (deflated 46%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/checkpoints/checkpoint-6/training_args.bin (deflated 53%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/logs/ (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/model_trainer/logs/events.out.tfevents.1761406832.8885ad095bd6.2523.0 (deflated 62%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/ (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/dataset/ (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/dataset/cache-0d2e7229aa609d22.arrow (deflated 78%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/dataset/data-00000-of-00001.arrow (deflated 60%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/dataset/dataset_info.json (deflated 74%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/dataset/state.json (deflated 38%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/cache/ (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/cache/abisee___cnn_dailymail/ (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/cache/abisee___cnn_dailymail/3.0.0/ (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/cache/abisee___cnn_dailymail/3.0.0/0.0.0/ (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/cache/abisee___cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d.incomplete_info.lock (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/cache/abisee___cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d_builder.lock (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/cache/abisee___cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/ (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/cache/abisee___cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cnn_dailymail-test.arrow (deflated 62%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/cache/abisee___cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/dataset_info.json (deflated 70%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/cache/abisee___cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cnn_dailymail-train-00001-of-00003.arrow (deflated 62%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/cache/abisee___cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cnn_dailymail-train-00002-of-00003.arrow (deflated 62%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/cache/abisee___cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cnn_dailymail-validation.arrow (deflated 62%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/cache/abisee___cnn_dailymail/3.0.0/0.0.0/96df5e686bee6baa90b8bee7c28b81fa3fa6223d/cnn_dailymail-train-00000-of-00003.arrow (deflated 61%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_ingestion/cache/artifacts_data_ingestion_cache_abisee___cnn_dailymail_3.0.0_0.0.0_96df5e686bee6baa90b8bee7c28b81fa3fa6223d.lock (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_transformation/ (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_transformation/tokenized_dataset/ (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_transformation/tokenized_dataset/data-00000-of-00001.arrow (deflated 78%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_transformation/tokenized_dataset/dataset_info.json (deflated 75%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_transformation/tokenized_dataset/cache-f8bcfc85bd5bd95a.arrow (deflated 49%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_transformation/tokenized_dataset/state.json (deflated 38%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_transformation/tokenized_dataset/cache-75e5ff1fd11c4790.arrow (deflated 64%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_transformation/tokenizer/ (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_transformation/tokenizer/merges.txt (deflated 53%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_transformation/tokenizer/vocab.json (deflated 59%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_transformation/tokenizer/special_tokens_map.json (deflated 52%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_transformation/tokenizer/tokenizer_config.json (deflated 75%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_transformation/tokenizer/tokenizer.json (deflated 82%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_validation/ (stored 0%)\n",
            "  adding: content/Text_Summarizer/artifacts/data_validation/status.txt (stored 0%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1c029de0-f2ef-4563-998f-9bfa29aa8769\", \"artifacts.zip\", 6462283694)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}